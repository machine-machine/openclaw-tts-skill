version: "3.9"

# m2 Voice Stack - Qwen3-TTS with RTX 3090
# Deploy via Coolify to voice.machinemachine.ai

services:
  # Qwen3-TTS Backend (GPU)
  qwen-tts:
    build:
      context: ./tts-server
      dockerfile: Dockerfile
      args:
        HF_TOKEN: ${HUGGING_FACE_HUB_TOKEN}
    container_name: m2-qwen-tts
    restart: unless-stopped
    shm_size: "8g"
    environment:
      - TZ=UTC
      - CUDA_VISIBLE_DEVICES=1
      - HF_TOKEN=${HUGGING_FACE_HUB_TOKEN}
      - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN}
      - MODEL_ID=Qwen/Qwen3-TTS
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["1"]
              capabilities: [gpu]
    volumes:
      - hf-cache:/root/.cache/huggingface
    healthcheck:
      test: ["CMD", "curl", "-sf", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 180s

  # Gateway API
  speech-gateway:
    build:
      context: ./gateway
      dockerfile: Dockerfile
    container_name: m2-voice-gateway
    restart: unless-stopped
    environment:
      - TTS_BASE_URL=http://qwen-tts:8000
      - TTS_TYPE=openai
      - PUBLIC_URL=https://voice.machinemachine.ai
      - STORAGE_DIR=/app/output
    volumes:
      - tts-output:/app/output
    depends_on:
      - qwen-tts
    healthcheck:
      test: ["CMD", "curl", "-sf", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

volumes:
  hf-cache:
  tts-output:
